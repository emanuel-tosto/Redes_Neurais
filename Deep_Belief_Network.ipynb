{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=center><font size = 5>Deep Belief Network </font></h1>\n",
    "\n",
    "Os __DBNs__ podem ser divididos em duas partes principais. O primeiro deles são múltiplas camadas de RBMs (Restricted Boltzmann Machines) para pré-treinar nossa rede. O segundo é uma rede backpropagation, que irá refinar ainda mais os resultados da pilha RBM.\n",
    "\n",
    "<img src=\"dbn.jpg\" alt=\"DBN Model\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#math para calculos\n",
    "import math\n",
    "#Tensorflow para os modelos de machine learn\n",
    "import tensorflow as tf\n",
    "#Numpy para calculos matematicos\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para implementar a rede DBN , implementarei uma classe para as Máquinas Restritas da Boltzmann (RBM). A classe abaixo implementa uma maneira de criar e usar RBMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definindo a classe maquina de boltzman restrita\n",
    "class RBM(object):\n",
    "\n",
    "    def __init__(self, input_size, output_size):\n",
    "        # definindo hiperparametros\n",
    "        self._input_size = input_size\n",
    "        self._output_size = output_size\n",
    "        self.epochs = 5  # numero de interacoes do treino\n",
    "        self.learning_rate = 1.0  # passo usado no gradiente descendente\n",
    "        self.batchsize = 100  # quantia de dados a serem usados no treino por sub-interacao\n",
    "\n",
    "        # Iniciando os pesos e bias como matrizes de zeros\n",
    "        self.w = np.zeros([input_size, output_size], np.float32)  # inicializando os pesos com zero\n",
    "        self.hb = np.zeros([output_size], np.float32)  # inicializando as bias ocultas com zero\n",
    "        self.vb = np.zeros([input_size], np.float32)  # inicializando as bias visiveis com zero\n",
    "\n",
    "    # ajustando o resultado da camada visivel(aplicada a esta os pesos) e as bias, em uma curva sigmoid\n",
    "    def prob_h_given_v(self, visible, w, hb):\n",
    "        # Sigmoid\n",
    "        return tf.nn.sigmoid(tf.matmul(visible, w) + hb)\n",
    "\n",
    "    # ajustando o resultado da camada oculta(aplicada a esta os pesos) e as bias, em uma curva sigmoid\n",
    "    def prob_v_given_h(self, hidden, w, vb):\n",
    "        return tf.nn.sigmoid(tf.matmul(hidden, tf.transpose(w)) + vb)\n",
    "\n",
    "    # gerando a probabilidade por amostra\n",
    "    def sample_prob(self, probs):\n",
    "        return tf.nn.relu(tf.sign(probs - tf.random_uniform(tf.shape(probs))))#Adicionando nao linearidade, transformacao linear onde tod mudanca nos inputs e proporcional as dos outputs\n",
    "\n",
    "    # metodo de treino para o modelo\n",
    "    def train(self, X):\n",
    "        # criando espaco exclusivo para os parametros\n",
    "        _w = tf.placeholder(\"float\", [self._input_size, self._output_size])\n",
    "        _hb = tf.placeholder(\"float\", [self._output_size])\n",
    "        _vb = tf.placeholder(\"float\", [self._input_size])\n",
    "\n",
    "        anterior_w = np.zeros([self._input_size, self._output_size],\n",
    "                         np.float32)  # Creates and initializes the weights with 0\n",
    "        anterior_hb = np.zeros([self._output_size], np.float32)  # Cria e inicializa as bias ocultas com 0\n",
    "        anterior_vb = np.zeros([self._input_size], np.float32)  # Cria e inicializa as bias visíveis com 0\n",
    "\n",
    "        atual_w = np.zeros([self._input_size, self._output_size], np.float32)\n",
    "        atual_hb = np.zeros([self._output_size], np.float32)\n",
    "        atual_vb = np.zeros([self._input_size], np.float32)\n",
    "        v0 = tf.placeholder(\"float\", [None, self._input_size])\n",
    "\n",
    "        # inicializando com as probabilidades por amostra\n",
    "        h0 = self.sample_prob(self.prob_h_given_v(v0, _w, _hb))\n",
    "        v1 = self.sample_prob(self.prob_v_given_h(h0, _w, _vb))\n",
    "        h1 = self.prob_h_given_v(v1, _w, _hb)\n",
    "\n",
    "        # criando gradientes\n",
    "        positive_grad = tf.matmul(tf.transpose(v0), h0)\n",
    "        negative_grad = tf.matmul(tf.transpose(v1), h1)\n",
    "\n",
    "        # atualizando a taxa(pontuacao) de aprendizado por camada\n",
    "        update_w = _w + self.learning_rate * (positive_grad - negative_grad) / tf.to_float(tf.shape(v0)[0])\n",
    "        update_vb = _vb + self.learning_rate * tf.reduce_mean(v0 - v1, 0)\n",
    "        update_hb = _hb + self.learning_rate * tf.reduce_mean(h0 - h1, 0)\n",
    "\n",
    "        # calcular erro\n",
    "        err = tf.reduce_mean(tf.square(v0 - v1))\n",
    "\n",
    "        # loop do treino\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            # para cada epoch\n",
    "            for epoch in range(self.epochs):\n",
    "                # para cada passo step/batch\n",
    "                for start, end in zip(range(0, len(X), self.batchsize), range(self.batchsize, len(X), self.batchsize)):\n",
    "                    batch = X[start:end]\n",
    "                    # atualizando pontuacao\n",
    "                    atual_w = sess.run(update_w, feed_dict={v0: batch, _w: anterior_w, _hb: anterior_hb, _vb: anterior_vb})\n",
    "                    atual_hb = sess.run(update_hb, feed_dict={v0: batch, _w: anterior_w, _hb: anterior_hb, _vb: anterior_vb})\n",
    "                    atual_vb = sess.run(update_vb, feed_dict={v0: batch, _w: anterior_w, _hb: anterior_hb, _vb: anterior_vb})\n",
    "                    anterior_w = atual_w\n",
    "                    anterior_hb = atual_hb\n",
    "                    anterior_vb = atual_vb\n",
    "                error = sess.run(err, feed_dict={v0: X, _w: atual_w, _vb: atual_vb, _hb: atual_hb})\n",
    "                print ('Epoch: %d' % epoch, 'reconstruction error: %f' % error)\n",
    "            self.w = anterior_w\n",
    "            self.hb = anterior_hb\n",
    "            self.vb = anterior_vb\n",
    "\n",
    "    # saida necessaria para a DBN\n",
    "    def rbm_outpt(self, X):\n",
    "        input_X = tf.constant(X)\n",
    "        _w = tf.constant(self.w)\n",
    "        _hb = tf.constant(self.hb)\n",
    "        out = tf.nn.sigmoid(tf.matmul(input_X, _w) + _hb)\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            return sess.run(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-af4aab2ebc58>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\Emanuel Vasconcelos\\Documents\\miniconda3\\envs\\ambiente\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\Emanuel Vasconcelos\\Documents\\miniconda3\\envs\\ambiente\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Emanuel Vasconcelos\\Documents\\miniconda3\\envs\\ambiente\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Emanuel Vasconcelos\\Documents\\miniconda3\\envs\\ambiente\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Emanuel Vasconcelos\\Documents\\miniconda3\\envs\\ambiente\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "#Carregando os dados\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)\n",
    "trX, trY, teX, teY = mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBM:  0   784 -> 500\n",
      "RBM:  1   500 -> 200\n",
      "RBM:  2   200 -> 50\n"
     ]
    }
   ],
   "source": [
    "#Criando a DBN\n",
    "RBM_hidden_sizes = [500, 200 , 50 ] #cria 3 RBMs, uma com 500 unidades ocultas, segunda com 200 e a ultima com 50 \n",
    "#Inputs serao os dados de treino\n",
    "inpX = trX\n",
    "\n",
    "#Criando lista para guardar as RBMs\n",
    "rbm_list = []\n",
    "\n",
    "#Tamanho das entradas é o número de entradas no conjunto de treinamento\n",
    "input_size = inpX.shape[1]\n",
    "\n",
    "#Para cada RBM sera inicializada atribuindo o tamnaho do conj treino e o numero de unidades ocultas,para segunda RBM o tamanho do conj treino recebera o valor do numero de unidades ocultas da camada anterior, assim por diante\n",
    "for i, size in enumerate(RBM_hidden_sizes):\n",
    "    print ('RBM: ',i,' ',input_size,'->', size)\n",
    "    rbm_list.append(RBM(input_size, size))\n",
    "    input_size = size #Serve para forcar compressao dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New RBM:\n",
      "WARNING:tensorflow:From <ipython-input-2-1a25c85c086b>:57: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch: 0 reconstruction error: 0.060681\n",
      "Epoch: 1 reconstruction error: 0.052861\n",
      "Epoch: 2 reconstruction error: 0.048948\n",
      "Epoch: 3 reconstruction error: 0.047465\n",
      "Epoch: 4 reconstruction error: 0.045820\n",
      "New RBM:\n",
      "Epoch: 0 reconstruction error: 0.035045\n",
      "Epoch: 1 reconstruction error: 0.030750\n",
      "Epoch: 2 reconstruction error: 0.028657\n",
      "Epoch: 3 reconstruction error: 0.027566\n",
      "Epoch: 4 reconstruction error: 0.027030\n",
      "New RBM:\n",
      "Epoch: 0 reconstruction error: 0.056838\n",
      "Epoch: 1 reconstruction error: 0.052835\n",
      "Epoch: 2 reconstruction error: 0.051468\n",
      "Epoch: 3 reconstruction error: 0.050643\n",
      "Epoch: 4 reconstruction error: 0.050701\n"
     ]
    }
   ],
   "source": [
    "#para cada RBM iniciar o treinar, uasando sempre como entrada de treino da proxima RBM o output da anterior\n",
    "for rbm in rbm_list:\n",
    "    print ('New RBM:')\n",
    "    #treinando nova RBM\n",
    "    rbm.train(inpX) \n",
    "    #Retornando output\n",
    "    inpX = rbm.rbm_outpt(inpX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Com a DBN treinada cria-se a Rede neural que fara uso das RBMs da DBN\n",
    "class NN(object):\n",
    "    \n",
    "    def __init__(self, sizes, X, Y):\n",
    "        #Inicializando hyperparametros\n",
    "        self._sizes = sizes\n",
    "        self._X = X\n",
    "        self._Y = Y\n",
    "        self.w_list = []\n",
    "        self.b_list = []\n",
    "        self._learning_rate =  1.0\n",
    "        self._momentum = 0.0\n",
    "        self._epoches = 10\n",
    "        self._batchsize = 100\n",
    "        input_size = X.shape[1]\n",
    "        \n",
    "        #Loop de iinicializacao\n",
    "        for size in self._sizes + [Y.shape[1]]:\n",
    "            #Definindo limite superior da distribuicao uniforme\n",
    "            max_range = 4 * math.sqrt(6. / (input_size + size))\n",
    "            \n",
    "            #Inicializando os pesos como uma distribuicao uniforme aleatoria\n",
    "            self.w_list.append(\n",
    "                np.random.uniform( -max_range, max_range, [input_size, size]).astype(np.float32))\n",
    "            \n",
    "            #Inicializando as bias como zeros\n",
    "            self.b_list.append(np.zeros([size], np.float32))\n",
    "            input_size = size\n",
    "      \n",
    "    #lendo dados da RBm\n",
    "    def load_from_rbms(self, dbn_sizes,rbm_list):\n",
    "        #Checando os tamanhos esperados\n",
    "        assert len(dbn_sizes) == len(self._sizes)\n",
    "        \n",
    "        for i in range(len(self._sizes)):\n",
    "            #Checando para cada RBM se o tamanho esta correto\n",
    "            assert dbn_sizes[i] == self._sizes[i]\n",
    "        \n",
    "        #Carregando bias e pesos\n",
    "        for i in range(len(self._sizes)):\n",
    "            self.w_list[i] = rbm_list[i].w\n",
    "            self.b_list[i] = rbm_list[i].hb\n",
    "\n",
    "    #treino \n",
    "    def train(self):\n",
    "        print()\n",
    "        #Cria espaçcs reservados para entrada, pesos, bias, saidas\n",
    "        _a = [None] * (len(self._sizes) + 2)\n",
    "        _w = [None] * (len(self._sizes) + 1)\n",
    "        _b = [None] * (len(self._sizes) + 1)\n",
    "        _a[0] = tf.placeholder(\"float\", [None, self._X.shape[1]])\n",
    "        y = tf.placeholder(\"float\", [None, self._Y.shape[1]])\n",
    "        \n",
    "        #Definindo variaveis e funcoes de ativacoes\n",
    "        for i in range(len(self._sizes) + 1):\n",
    "            _w[i] = tf.Variable(self.w_list[i])\n",
    "            _b[i] = tf.Variable(self.b_list[i])\n",
    "        for i in range(1, len(self._sizes) + 2):\n",
    "            _a[i] = tf.nn.sigmoid(tf.matmul(_a[i - 1], _w[i - 1]) + _b[i - 1])\n",
    "        \n",
    "        #Funcao custo\n",
    "        cost = tf.reduce_mean(tf.square(_a[-1] - y))\n",
    "        \n",
    "        #Definindo operacao de treino (Momentum Optimizer minimizing the Cost function)\n",
    "        train_op = tf.train.MomentumOptimizer(self._learning_rate, self._momentum).minimize(cost)\n",
    "        \n",
    "        #Operacao de predicao\n",
    "        predict_op = tf.argmax(_a[-1], 1)\n",
    "        \n",
    "        #Loop de treino\n",
    "        with tf.Session() as sess:\n",
    "            #Initicializando variaveis\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "            #Para cada epoca\n",
    "            for i in range(self._epoches):\n",
    "                print(\"is here\")\n",
    "                #Para cada passo\n",
    "                for start, end in zip(range(0, len(self._X), self._batchsize), range(self._batchsize, len(self._X), self._batchsize)):\n",
    "                    \n",
    "                    #Executando operacao de treino em cada input\n",
    "                    sess.run(train_op, feed_dict={ _a[0]: self._X[start:end], y: self._Y[start:end]})\n",
    "                \n",
    "                for j in range(len(self._sizes) + 1):\n",
    "                    #recuperando pesos e bias\n",
    "                    self.w_list[j] = sess.run(_w[j])\n",
    "                    self.b_list[j] = sess.run(_b[j])\n",
    "                \n",
    "                print (\"Precisao por epoca \" + str(i) + \": \" + str(np.mean(np.argmax(self._Y, axis=1) == sess.run(predict_op, feed_dict={_a[0]: self._X, y: self._Y}))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Emanuel Vasconcelos\\Documents\\miniconda3\\envs\\ambiente\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "is here\n",
      "Precisao por epoca 0: 0.49334545454545453\n",
      "is here\n",
      "Precisao por epoca 1: 0.6391272727272728\n",
      "is here\n",
      "Precisao por epoca 2: 0.7171636363636363\n",
      "is here\n",
      "Precisao por epoca 3: 0.7567272727272727\n",
      "is here\n",
      "Precisao por epoca 4: 0.7858909090909091\n",
      "is here\n",
      "Precisao por epoca 5: 0.8438727272727272\n",
      "is here\n",
      "Precisao por epoca 6: 0.8820727272727272\n",
      "is here\n",
      "Precisao por epoca 7: 0.8942181818181818\n",
      "is here\n",
      "Precisao por epoca 8: 0.9032181818181818\n",
      "is here\n",
      "Precisao por epoca 9: 0.9095454545454545\n"
     ]
    }
   ],
   "source": [
    "Rede_Neural = NN(RBM_hidden_sizes, trX, trY)\n",
    "Rede_Neural.load_from_rbms(RBM_hidden_sizes,rbm_list)\n",
    "Rede_Neural.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
